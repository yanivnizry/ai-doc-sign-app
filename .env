# Local LLM Configuration (Ollama)
EXPO_PUBLIC_LOCAL_LLM_URL=http://192.168.0.207:11434
EXPO_PUBLIC_LOCAL_LLM_MODEL=huihui_ai/granite3.2-vision-abliterated

# Optional: Configure max tokens for AI responses (default: 3000)
EXPO_PUBLIC_LOCAL_LLM_MAX_TOKENS=3000

# Grok API (commented out - using local LLM instead)
# EXPO_PUBLIC_GROK_API_KEY=your_grok_api_key_here
